{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d939b8a-da08-4d4f-9868-7474f8e3a919",
   "metadata": {},
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models, regularizers, backend as K\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b5448a-ac46-40d0-a150-4f0aec9deb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = \"covid19-radiography-database.zip\"\n",
    "if os.path.exists(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb8de0-4643-4f04-91b0-87e7dba6ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# GPU memory safety (Jupyter)\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56330a75-7503-4ad3-9c8f-15d95e54562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"COVID-19_Radiography_Dataset\"\n",
    "MODEL_DIR = \"./saved_models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.listdir(data_dir)\n",
    "cat = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c5aee-b5ee-4b19-bf00-6df4c08be7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5435e55-e562-451b-a45b-65983bec3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image(filename):\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    return any(filename.lower().endswith(ext) for ext in image_extensions)\n",
    "\n",
    "for category in cat:\n",
    "    path = os.path.join(data_dir, category, 'images')\n",
    "    images = [f for f in os.listdir(path) if is_image(f)]\n",
    "\n",
    "    if not images:\n",
    "        print(f\"No images found in {path}\")\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(10, 4))\n",
    "    fig.suptitle(f'{category}', fontsize=18)\n",
    "    for i in range(5):\n",
    "        img_name = images[np.random.randint(0, len(images))]\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        img_array = cv2.imread(img_path)\n",
    "        if img_array is None:\n",
    "            print(f\"Error: Could not load image {img_path}\")\n",
    "            continue\n",
    "\n",
    "        ax[i].imshow(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))\n",
    "        ax[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b40c43-1cd4-4f59-8f45-299f109e2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c43fb551-2cfb-4fc4-a695-17e51df3b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "def create_train_data():\n",
    "    for category in cat:\n",
    "        path = os.path.join(data_dir, category, 'images')\n",
    "        labels = cat.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img))\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, labels])\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e6176-d8eb-4b4a-90f1-59d5c9370130",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_counts = {}\n",
    "for category in cat:\n",
    "    path = os.path.join(data_dir, category, 'images')\n",
    "    files = os.listdir(path)\n",
    "    file_counts[category] = len(files)\n",
    "\n",
    "for category, count in file_counts.items():\n",
    "    print(f\"{category}: {count} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0eb40f-112e-444f-972c-31d8286f1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, labels in training_data:\n",
    "    X.append(features)\n",
    "    y.append(labels)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "print(f'X_train Length : {X_train.shape[0]}, X_train Image size : {X_train.shape[1:3]}, Channel Dimension : {X_train.shape[3]}')\n",
    "print(f'X_test Length : {X_test.shape[0]}, X_test Image size : {X_test.shape[1:3]}, Channel Dimension : {X_test.shape[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f00805a-90ff-4864-8eee-4276213a7e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(images, patch_size):\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, patch_size, patch_size, 1],\n",
    "        strides=[1, patch_size, patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding='VALID'\n",
    "    )\n",
    "\n",
    "    patches = tf.reshape(patches, (patches.shape[0], -1, patch_size * patch_size * 3))\n",
    "    return patches\n",
    "\n",
    "patch_size = 8\n",
    "X_train_patches = create_patches(X_train, patch_size)\n",
    "X_test_patches = create_patches(X_test, patch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bcf4dd-997c-44e3-888b-73e3d44dbd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_input = layers.Input(shape=(128, 128, 3))\n",
    "\n",
    "x = layers.Rescaling(1.0 / 255)(cnn_input)\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "#x = se_block(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "#x = se_block(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=512, kernel_size=3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "#x = se_block(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.02))(x)\n",
    "cnn_branch = layers.Dropout(0.5)(x)\n",
    "\n",
    "rnn_input = layers.Input(shape=(256, 192))\n",
    "y = layers.Bidirectional(layers.LSTM(64, activation='tanh'))(rnn_input)\n",
    "rnn_branch = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(y)\n",
    "rnn_branch = layers.Dropout(0.3)(rnn_branch)\n",
    "\n",
    "\n",
    "merged = layers.Concatenate()([cnn_branch, rnn_branch])\n",
    "merged = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(merged)\n",
    "output = layers.Dense(4, activation='softmax')(merged)\n",
    "\n",
    "combined_model = models.Model(inputs=[cnn_input, rnn_input], outputs=output)\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb84385d-760f-40ae-b45a-69600dd19d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "combined_model.compile(loss='sparse_categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "840f7483-0a28-4881-b0db-f67499a9d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStopping = tf.keras.callbacks.EarlyStopping\n",
    "ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-5\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c6f3a11-6e2c-4305-b869-d0a73b7681f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "Callback = tf.keras.callbacks.Callback\n",
    "\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch_times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch_times.append(time.time() - self.start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32608c9f-a565-4425-823a-83886d61cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_callback = TimeHistory()\n",
    "\n",
    "history = combined_model.fit(\n",
    "    x=[X_train, X_train_patches],\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_data=([X_test, X_test_patches], y_test),\n",
    "    callbacks=[ model_checkpoint, reduce_lr, time_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef87a63-b3e8-4e7b-96d8-efcd584f305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = models.Model(inputs=[cnn_input, rnn_input], outputs=output)\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c76d8-c027-42eb-bcd5-d11abeabcec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.load_weights(\"best_model.keras\")\n",
    "combined_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1fd61a-897b-4cf9-bba8-71d88f563ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = combined_model.evaluate(\n",
    "    [X_train, X_train_patches],\n",
    "    y_train,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "\n",
    "test_loss, test_acc = combined_model.evaluate(\n",
    "    [X_test, X_test_patches],\n",
    "    y_test,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522de464-890b-42f4-85d9-cd6d8d6b60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred = combined_model.predict([X_test, X_test_patches])\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred_classes,\n",
    "    digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7872f26-51cd-4be9-a84d-ab06ec450c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy plot\n",
    "y_test[:5]\n",
    "pred = np.argmax(combined_model.predict([X_test, X_test_patches]), axis = -1)\n",
    "\n",
    "pred[:5]\n",
    "\n",
    "print(classification_report(y_test, pred, digits = 3))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385e2fd-aa67-4c43-bb40-3a1e9b837427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average training time per epoch\n",
    "avg_time_per_epoch = np.mean(time_callback.epoch_times)\n",
    "print(f\"Average training time per epoch: {avg_time_per_epoch:.2f} s/epoch\")\n",
    "\n",
    "total_time = np.sum(time_callback.epoch_times)\n",
    "print(f\"Total training time for 100 epochs: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f1d22-d8a3-4103-a82a-5db92c8065a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_test_onehot = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "y_pred_probs = combined_model.predict([X_test, X_test_patches])\n",
    "\n",
    "auc_macro = roc_auc_score(\n",
    "    y_test_onehot,\n",
    "    y_pred_probs,\n",
    "    multi_class=\"ovr\",\n",
    "    average=\"macro\"\n",
    ")\n",
    "\n",
    "auc_weighted = roc_auc_score(\n",
    "    y_test_onehot,\n",
    "    y_pred_probs,\n",
    "    multi_class=\"ovr\",\n",
    "    average=\"weighted\"\n",
    ")\n",
    "\n",
    "print(\"Macro AUC:\", auc_macro)\n",
    "print(\"Weighted AUC:\", auc_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3990e5f-31b8-42f4-8d40-d0e34c876222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = np.argmax(combined_model.predict([X_test, X_test_patches]), axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cat)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
